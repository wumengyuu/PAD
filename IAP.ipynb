{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T15:28:39.182781500Z",
     "start_time": "2025-04-06T15:28:39.173433100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points:  517\n",
      "Number of features:  11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anomalous_edited import *\n",
    "from function import *\n",
    "\n",
    "df = pd.read_csv('forestfires.csv')\n",
    "\n",
    "#Test to see which one is better\n",
    "#df_normalized = normalization_zscore(df)\n",
    "##df_normalized = normalization_range(df)\n",
    "\n",
    "#number of data points\n",
    "nn = df.shape[0]\n",
    "#number of features\n",
    "mm = df.shape[1]\n",
    "\n",
    "print(\"Number of data points: \", nn)\n",
    "print(\"Number of features: \", mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [4.669245647969052, 4.299806576402321, 90.64468085106384, 110.87234042553192, 547.9400386847195, 9.021663442940039, 18.88916827852998, 44.28820116054158, 4.017601547388782, 0.021663442940038684, 12.847292069632493]\n",
      "Max:  [9, 9, 96.2, 291.3, 860.6, 56.1, 33.3, 100, 9.4, 6.4, 1090.84]\n",
      "Min:  [1, 2, 18.7, 1.1, 7.9, 0.0, 2.2, 15, 0.4, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Calculate global statistics\n",
    "me = [np.mean(df.iloc[:, j]) for j in range(mm)]\n",
    "mmax = [np.max(df.iloc[:, j]) for j in range(mm)]\n",
    "mmin = [np.min(df.iloc[:, j]) for j in range(mm)]\n",
    "ranges = []\n",
    "normalization = 0  # set to 1 to ignore feature ranges, 0 otherwise\n",
    "for j in range(mm):\n",
    "    if normalization:\n",
    "        ranges.append(1)\n",
    "    else:\n",
    "        rng = mmax[j] - mmin[j]\n",
    "        if rng == 0:\n",
    "            print(\"Variable num {} is constant!\".format(j))\n",
    "            rng = 1\n",
    "        ranges.append(rng)\n",
    "\n",
    "sy = np.divide((df - me), ranges)\n",
    "sY = np.array(sy)\n",
    "d = np.sum(sY * sY)   # total data scatter of normalized data\n",
    "\n",
    "print(\"Mean: \", me)\n",
    "print(\"Max: \", mmax)\n",
    "print(\"Min: \", mmin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T15:29:54.365918600Z",
     "start_time": "2025-04-06T15:29:54.353937300Z"
    }
   },
   "id": "b7291ca734e0c87b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: (slice(None, None, None), 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m ancl \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# each element: {'cluster': list, 'centroid': list, 'dD': float}\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(remains) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 10\u001B[0m     distance \u001B[38;5;241m=\u001B[39m \u001B[43mdist\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mremains\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mranges\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mme\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# finding normalised distance vector from remains data points to reference 'me'\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     ind \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(distance)\n\u001B[0;32m     12\u001B[0m     index \u001B[38;5;241m=\u001B[39m remains[ind]\n",
      "File \u001B[1;32m~\\PycharmProjects\\PAD\\anomalous_edited.py:119\u001B[0m, in \u001B[0;36mdist\u001B[1;34m(x, remains, ranges, p)\u001B[0m\n\u001B[0;32m    117\u001B[0m distan \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((rr,\u001B[38;5;241m1\u001B[39m))    \n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(mm):\n\u001B[1;32m--> 119\u001B[0m     z \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39miloc[:, j]         \u001B[38;5;66;03m# j feature vector\u001B[39;00m\n\u001B[0;32m    120\u001B[0m     z \u001B[38;5;241m=\u001B[39m z\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    121\u001B[0m     zz \u001B[38;5;241m=\u001B[39m z[remains]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3811\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[1;32m-> 3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m   3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "# Iterative Anomalous Cluster Algorithm\n",
    "remains = list(range(nn))  # indices of remaining points\n",
    "threshold = 25  # minimum cluster size\n",
    "numberC = 0  # counter of anomalous clusters\n",
    "\n",
    "# Instead of a single array, store clusters as a list of dictionaries:\n",
    "ancl = []  # each element: {'cluster': list, 'centroid': list, 'dD': float}\n",
    "\n",
    "while len(remains) > 0:\n",
    "    distance = dist(df, remains, ranges, me) # finding normalised distance vector from remains data points to reference 'me'\n",
    "    ind = np.argmax(distance)\n",
    "    index = remains[ind]\n",
    "    centroid = df[index, :]   # initial anomalous center reference point: the one with higher distance\n",
    "    numberC = numberC + 1\n",
    "    \n",
    "    (cluster, centroid) = anomalousPattern(df, remains, ranges, centroid, me) # finding AP cluster\n",
    "    \n",
    "    \n",
    "    censtand = np.divide((np.asarray(centroid) - me), np.asarray(ranges)) # standardised centroid with parameters of the data   \n",
    "    dD = np.sum(np.divide(censtand * censtand.T * len(cluster) * 100, d)) # cluster contribution (per cent) - (lecture on K-means and iK-means)\n",
    "\n",
    "    remains = np.setdiff1d(remains, cluster) \n",
    "    # update the data structure that keeps everything together\n",
    "    ancl.append(cluster)   # set of data points in the cluster\n",
    "    ancl.append(censtand)  # standardised centroid\n",
    "    ancl.append(dD) # proportion of the data scatter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T15:34:28.830656100Z",
     "start_time": "2025-04-06T15:34:28.784751400Z"
    }
   },
   "id": "6406d8dac102be0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter clusters by threshold size\n",
    "filtered_ancl = [ac for ac in ancl if len(ac['cluster']) >= threshold]\n",
    "\n",
    "if len(filtered_ancl) == 0:\n",
    "    print('Too great a threshold!!!')\n",
    "else:\n",
    "    # For demonstration, print out the clusters and their standardized centroids\n",
    "    for i, ac in enumerate(filtered_ancl):\n",
    "        print(f\"Cluster {i + 1}:\")\n",
    "        print(\"  Size:\", len(ac['cluster']))\n",
    "        print(\"  Centroid (standardized):\", np.round(ac['centroid'], 3))\n",
    "        print(\"  Cluster contribution (%):\", np.round(ac['dD'], 3))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf6ab39d628acde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
