{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:59:29.690227Z",
     "start_time": "2025-04-06T17:59:29.679406Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points:  517\n",
      "Number of features:  11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anomalous_edited import *\n",
    "from function import *\n",
    "\n",
    "df = pd.read_csv('forestfires.csv')\n",
    "\n",
    "#Test to see which one is better\n",
    "#df_normalized = normalization_zscore(df)\n",
    "##df_normalized = normalization_range(df)\n",
    "\n",
    "#number of data points\n",
    "nn = df.shape[0]\n",
    "#number of features\n",
    "mm = df.shape[1]\n",
    "\n",
    "print(\"Number of data points: \", nn)\n",
    "print(\"Number of features: \", mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7291ca734e0c87b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:59:29.727033Z",
     "start_time": "2025-04-06T17:59:29.712515Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [np.float64(4.669245647969052), np.float64(4.299806576402321), np.float64(90.64468085106384), np.float64(110.87234042553192), np.float64(547.9400386847195), np.float64(9.021663442940039), np.float64(18.88916827852998), np.float64(44.28820116054158), np.float64(4.017601547388782), np.float64(0.021663442940038684), np.float64(12.847292069632493)]\n",
      "Max:  [np.int64(9), np.int64(9), np.float64(96.2), np.float64(291.3), np.float64(860.6), np.float64(56.1), np.float64(33.3), np.int64(100), np.float64(9.4), np.float64(6.4), np.float64(1090.84)]\n",
      "Min:  [np.int64(1), np.int64(2), np.float64(18.7), np.float64(1.1), np.float64(7.9), np.float64(0.0), np.float64(2.2), np.int64(15), np.float64(0.4), np.float64(0.0), np.float64(0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate global statistics\n",
    "me = [np.mean(df.iloc[:, j]) for j in range(mm)]\n",
    "mmax = [np.max(df.iloc[:, j]) for j in range(mm)]\n",
    "mmin = [np.min(df.iloc[:, j]) for j in range(mm)]\n",
    "ranges = []\n",
    "normalization = 0  # set to 1 to ignore feature ranges, 0 otherwise\n",
    "for j in range(mm):\n",
    "    if normalization:\n",
    "        ranges.append(1)\n",
    "    else:\n",
    "        rng = mmax[j] - mmin[j]\n",
    "        if rng == 0:\n",
    "            print(\"Variable num {} is constant!\".format(j))\n",
    "            rng = 1\n",
    "        ranges.append(rng)\n",
    "\n",
    "sy = np.divide((df - me), ranges)\n",
    "sY = np.array(sy)\n",
    "d = np.sum(sY * sY)   # total data scatter of normalized data\n",
    "\n",
    "print(\"Mean: \", me)\n",
    "print(\"Max: \", mmax)\n",
    "print(\"Min: \", mmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406d8dac102be0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:59:29.781278Z",
     "start_time": "2025-04-06T17:59:29.748077Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Cluster 1 | Points remaining: 517\n",
      "✅ Cluster 1 done. Size: 102, Contribution: 22.5%\n",
      "⏳ Cluster 2 | Points remaining: 415\n",
      "✅ Cluster 2 done. Size: 1, Contribution: 0.68%\n",
      "⏳ Cluster 3 | Points remaining: 414\n",
      "✅ Cluster 3 done. Size: 154, Contribution: 11.22%\n",
      "⏳ Cluster 4 | Points remaining: 260\n",
      "✅ Cluster 4 done. Size: 1, Contribution: 0.5%\n",
      "⏳ Cluster 5 | Points remaining: 259\n",
      "✅ Cluster 5 done. Size: 153, Contribution: 12.36%\n",
      "⏳ Cluster 6 | Points remaining: 106\n",
      "✅ Cluster 6 done. Size: 34, Contribution: 2.64%\n",
      "⏳ Cluster 7 | Points remaining: 72\n",
      "✅ Cluster 7 done. Size: 1, Contribution: 0.3%\n",
      "⏳ Cluster 8 | Points remaining: 71\n",
      "✅ Cluster 8 done. Size: 10, Contribution: 0.61%\n",
      "⏳ Cluster 9 | Points remaining: 61\n",
      "✅ Cluster 9 done. Size: 44, Contribution: 1.04%\n",
      "⏳ Cluster 10 | Points remaining: 17\n",
      "✅ Cluster 10 done. Size: 3, Contribution: 0.2%\n",
      "⏳ Cluster 11 | Points remaining: 14\n",
      "✅ Cluster 11 done. Size: 1, Contribution: 0.11%\n",
      "⏳ Cluster 12 | Points remaining: 13\n",
      "✅ Cluster 12 done. Size: 1, Contribution: 0.11%\n",
      "⏳ Cluster 13 | Points remaining: 12\n",
      "✅ Cluster 13 done. Size: 5, Contribution: 0.28%\n",
      "⏳ Cluster 14 | Points remaining: 7\n",
      "✅ Cluster 14 done. Size: 4, Contribution: 0.27%\n",
      "⏳ Cluster 15 | Points remaining: 3\n",
      "✅ Cluster 15 done. Size: 1, Contribution: 0.05%\n",
      "⏳ Cluster 16 | Points remaining: 2\n",
      "✅ Cluster 16 done. Size: 1, Contribution: 0.02%\n",
      "⏳ Cluster 17 | Points remaining: 1\n",
      "✅ Cluster 17 done. Size: 1, Contribution: 0.02%\n",
      "\n",
      "🎉 Clustering complete!\n"
     ]
    }
   ],
   "source": [
    "x = df.values.astype(np.float32)\n",
    "remains = list(range(nn))\n",
    "threshold = 25\n",
    "numberC = 0\n",
    "ancl = []\n",
    "\n",
    "\n",
    "while len(remains) > 0:\n",
    "\n",
    "    # Step 1: Compute distance to the global mean\n",
    "    distance = dist(x, remains, ranges, me)\n",
    "\n",
    "    # Step 2: Choose the most distant point as centroid\n",
    "    ind = np.argmax(distance)\n",
    "    index = remains[ind]\n",
    "    centroid = x[index, :]\n",
    "\n",
    "    # Step 3: Run the anomalous pattern algorithm\n",
    "    cluster, centroid = anomalousPattern(x, remains, ranges, centroid, me)\n",
    "\n",
    "    if len(cluster) == 0:\n",
    "        break\n",
    "\n",
    "    # Step 4: Compute standardized centroid and contribution\n",
    "    censtand = np.divide((np.asarray(centroid) - me), np.asarray(ranges))\n",
    "    dD = np.sum(censtand * censtand.T * len(cluster) * 100 / d)\n",
    "\n",
    "    # Step 5: Store the result\n",
    "    ancl.append({\n",
    "        'cluster': cluster,\n",
    "        'centroid': censtand,\n",
    "        'dD': dD\n",
    "    })\n",
    "\n",
    "    # Step 6: Update remains\n",
    "    remains = np.setdiff1d(remains, cluster)\n",
    "    numberC += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6ab39d628acde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:59:29.815640Z",
     "start_time": "2025-04-06T17:59:29.806994Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:\n",
      "  Size: 102\n",
      "  Centroid (standardized): [ 0.032  0.026 -0.057 -0.287 -0.523 -0.061 -0.236  0.024  0.088 -0.003\n",
      " -0.006]\n",
      "  Cluster contribution (%): 22.504\n",
      "Cluster 2:\n",
      "  Size: 154\n",
      "  Centroid (standardized): [ 0.308  0.103  0.016  0.108  0.134  0.014  0.07  -0.013 -0.036 -0.001\n",
      "  0.009]\n",
      "  Cluster contribution (%): 11.224\n",
      "Cluster 3:\n",
      "  Size: 153\n",
      "  Centroid (standardized): [-0.319 -0.1    0.019  0.093  0.151  0.018  0.099 -0.048 -0.033 -0.003\n",
      " -0.002]\n",
      "  Cluster contribution (%): 12.363\n",
      "Cluster 4:\n",
      "  Size: 34\n",
      "  Centroid (standardized): [-0.014 -0.043 -0.02   0.022  0.151 -0.003 -0.143  0.303  0.113  0.005\n",
      " -0.007]\n",
      "  Cluster contribution (%): 2.638\n",
      "Cluster 5:\n",
      "  Size: 44\n",
      "  Centroid (standardized): [-0.01  -0.053  0.015 -0.04   0.177 -0.     0.019 -0.078 -0.061 -0.003\n",
      " -0.004]\n",
      "  Cluster contribution (%): 1.045\n"
     ]
    }
   ],
   "source": [
    "# Filter clusters by threshold size\n",
    "filtered_ancl = [ac for ac in ancl if len(ac['cluster']) >= threshold]\n",
    "\n",
    "if len(filtered_ancl) == 0:\n",
    "    print('Too great a threshold!!!')\n",
    "else:\n",
    "    # For demonstration, print out the clusters and their standardized centroids\n",
    "    for i, ac in enumerate(filtered_ancl):\n",
    "        print(f\"Cluster {i + 1}:\")\n",
    "        print(\"  Size:\", len(ac['cluster']))\n",
    "        print(\"  Centroid (standardized):\", np.round(ac['centroid'], 3))\n",
    "        print(\"  Cluster contribution (%):\", np.round(ac['dD'], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
